# adf_repo
_This repo contains ADF Assignemnt_

# ADF Assignment

## Setup Container and Folder Structure in ADLS

- **Description**: Create a container and folders in Azure Data Lake Storage (ADLS) to store the project data. The folders should be organized according to the data categories: customer, product, store, and sales.
- **Steps**:
  1. Create a container named `sales_view_devtst` in ADLS.
  2. Within the container, create four folders: customer, product, store, and sales.
  3. Upload the respective data files into each folder to facilitate real-time data processing.

## Create ADF Pipeline

- **Description**: Develop an Azure Data Factory (ADF) pipeline to retrieve the latest modified files from the folders in ADLS dynamically. Parameterize the pipeline to ensure it can handle files from any day.
- **Steps**:
  1. Create an ADF pipeline to extract data from the specified folders in ADLS.
  2. Implement parameterization to make the pipeline dynamic, allowing it to process files from any day.
  3. Ensure that necessary parameter values are passed to the pipeline for seamless execution.

## Bronze Layer Setup

- **Description**: Configure the Bronze layer in ADLS to store raw data copied from the ADF pipeline. Organize the data into folders corresponding to different data categories.
- **Steps**:
  1. Create a folder structure within the `Bronze` directory to mirror the data categories (customer, product, store, sales).
  2. Copy the raw data files generated by the ADF pipeline into their respective folders in the Bronze layer.

## Silver Layer Setup

- **Description**: Set up the Silver layer in ADLS to store processed data after applying transformations. Perform data transformations on customer, product, store, and sales data.
- **Steps**:
  1. Create a database named `sales_view` within the Silver layer.
  2. Within the `sales_view` database, create folders for each data category (customer, product, store, customer_sales).
  3. Apply specific transformations to each data category:
     - Customer: Convert column headers to snake case, split name column, extract domain from email, etc.
     - Product: Convert column headers to snake case, create sub-category column, etc.
     - Store: Convert column headers to snake case, create store category column, format date columns, etc.
     - Sales: Convert column headers to snake case, etc.
  4. Write the transformed data to respective tables within the Silver layer path.
  5. Utilize product and store tables to enrich the data.
  6. Read delta tables using User Defined Functions (UDFs) for data retrieval.
  7. Generate enriched data by combining information from customer_sales, product, and store tables.
  8. Write the enriched data to the `StoreProductSalesAnalysis` table within the Gold layer path.


- **File Structure**:
  - In ADLS:
    - Bronze Layer: Raw data folders (customer, product, store, sales).
    - Silver Layer: Processed data folders (customer, product, store, customer_sales).
  - In Databricks:
    - `bronze_to_silver`: Transformation and creation of Silver layer tables.
    - `silver_to_gold`: Further processing and creation of Gold layer tables.
